/**
 * Ù…ÙˆØªÙˆØ± Ø¬Ø³ØªØ¬ÙˆÛŒ Ø´Ø¨Ø§Ù‡Øª Ù…ØªÙ†ÛŒ Ø¨Ø±Ø§ÛŒ FAQ
 * Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Cosine Similarity Ùˆ TF-IDF
 */

class SimilaritySearch {
    constructor() {
        this.stopWords = this.getPersianStopWords();
        this.tokenCache = new Map();
    }
    
    // Ù„ÛŒØ³Øª Ú©Ù„Ù…Ø§Øª ØªÙˆÙ‚Ù ÙØ§Ø±Ø³ÛŒ
    getPersianStopWords() {
        return new Set([
            'Ø¯Ø±', 'Ø¨Ù‡', 'Ø§Ø²', 'Ú©Ù‡', 'Ø§ÛŒÙ†', 'Ø±Ø§', 'Ø¨Ø§', 'Ø§Ø³Øª', 'ÛŒÚ©', 'Ø¨Ø±Ø§ÛŒ',
            'Ø¢Ù†', 'Ù‡Ù…', 'Ø¨ÙˆØ¯', 'Ø´Ø¯', 'ØªØ§', 'Ú©Ø±Ø¯', 'Ø´Ø¯Ù‡', 'Ø´ÙˆØ¯', 'Ø¨Ø§Ø´Ø¯',
            'Ù‡Ø§ÛŒ', 'Ù‡Ø§ÛŒØ´', 'ØªØ±ÛŒÙ†', 'ØªØ±', 'Ù…ÛŒ', 'Ù‡Ø§ÛŒÙ…', 'Ù‡Ø§', 'Ùˆ', 'ÛŒØ§',
            'Ø§Ù…Ø§', 'Ø§Ú¯Ø±', 'Ú†ÙˆÙ†', 'Ú†Ù‡', 'Ù‡Ù…Ø§Ù†', 'Ù‡Ù…ÛŒÙ†', 'Ù‡Ù…Ù‡', 'Ù‡Ù…Ú†Ù†ÛŒÙ†',
            'Ø¨Ø±', 'Ø¨ÛŒ', 'Ú†Ù‡', 'Ø®ÙˆØ§Ù‡Ø¯', 'Ø¯ÛŒÚ¯Ø±', 'Ø±Ùˆ', 'Ø²ÛŒØ±', 'Ø³Ù¾Ø³', 'ØºÙ…',
            'Ù‚Ø¨Ù„', 'Ù„Ø§', 'Ù…Ú¯Ø±', 'Ù†Ù‡', 'ÙˆÙ„ÛŒ', 'Ù¾Ø³', 'Ú†Ø±Ø§', 'Ú†Ú¯ÙˆÙ†Ù‡', 'Ú©Ø¬Ø§',
            'Ú©Ø¯Ø§Ù…', 'Ú©Ø³', 'Ú©ÛŒ', 'Ú¯Ùˆ', 'Ú¯ÛŒØ±Ø¯', 'Ú¯ÙØª', 'ÛŒØ¹Ù†ÛŒ', 'Ø¢ÛŒØ§', 'Ø§Ù†Ø¯'
        ]);
    }
    
    // Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ†: Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒØŒ Ø­Ø°Ù Ø¹Ù„Ø§Ø¦Ù… Ùˆ tokenization
    preprocess(text) {
        const cacheKey = `preprocess:${text}`;
        if (this.tokenCache.has(cacheKey)) {
            return this.tokenCache.get(cacheKey);
        }
        
        // ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø­Ø±ÙˆÙ Ú©ÙˆÚ†Ú©
        let processed = text.toLowerCase();
        
        // Ø­Ø°Ù Ø¹Ù„Ø§Ø¦Ù… Ù†Ú¯Ø§Ø±Ø´ÛŒ
        processed = processed.replace(/[\.ØŒØ›:!?ØŸ,;'"`\[\]{}()<>]/g, ' ');
        
        // Ø­Ø°Ù Ø§Ø¹Ø¯Ø§Ø¯
        processed = processed.replace(/\d+/g, ' ');
        
        // Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
        processed = processed.replace(/\s+/g, ' ').trim();
        
        // tokenization
        const tokens = processed.split(' ').filter(token => token.length > 1);
        
        // Ø­Ø°Ù Ú©Ù„Ù…Ø§Øª ØªÙˆÙ‚Ù
        const filteredTokens = tokens.filter(token => !this.stopWords.has(token));
        
        // stem Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ø§Øª ÙØ§Ø±Ø³ÛŒ
        const stemmedTokens = filteredTokens.map(token => this.simpleStem(token));
        
        this.tokenCache.set(cacheKey, stemmedTokens);
        return stemmedTokens;
    }
    
    // stemming Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
    simpleStem(word) {
        // Ø­Ø°Ù Ù¾Ø³ÙˆÙ†Ø¯Ù‡Ø§ÛŒ Ø±Ø§ÛŒØ¬ ÙØ§Ø±Ø³ÛŒ
        const suffixes = ['Ù‡Ø§', 'Ù‡Ø§ÛŒ', 'ØªØ±ÛŒÙ†', 'ØªØ±', 'ÛŒ', 'Ø§Ù†', 'Ø§Øª', 'Ù…', 'Øª', 'Ø´'];
        
        for (const suffix of suffixes) {
            if (word.endsWith(suffix) && word.length > suffix.length + 1) {
                return word.slice(0, -suffix.length);
            }
        }
        
        return word;
    }
    
    // Ø³Ø§Ø®Øª Ø¨Ø±Ø¯Ø§Ø± TF Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù…ØªÙ†
    buildTFVector(tokens) {
        const vector = {};
        let maxFreq = 0;
        
        // Ø´Ù…Ø§Ø±Ø´ ÙØ±Ú©Ø§Ù†Ø³â€ŒÙ‡Ø§
        for (const token of tokens) {
            vector[token] = (vector[token] || 0) + 1;
            maxFreq = Math.max(maxFreq, vector[token]);
        }
        
        // Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ù‡ TF
        for (const token in vector) {
            vector[token] = vector[token] / maxFreq;
        }
        
        return vector;
    }
    
    // Ù…Ø­Ø§Ø³Ø¨Ù‡ IDF Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ù…Ø³ØªÙ†Ø¯Ø§Øª
    calculateIDF(documents) {
        const idf = {};
        const N = documents.length;
        
        for (const doc of documents) {
            const uniqueTokens = new Set(doc.tokens);
            for (const token of uniqueTokens) {
                idf[token] = (idf[token] || 0) + 1;
            }
        }
        
        // Ù…Ø­Ø§Ø³Ø¨Ù‡ IDF ÙˆØ§Ù‚Ø¹ÛŒ
        for (const token in idf) {
            idf[token] = Math.log(N / (idf[token] + 1)) + 1; // Smoothing
        }
        
        return idf;
    }
    
    // Ù…Ø­Ø§Ø³Ø¨Ù‡ Cosine Similarity Ø¨ÛŒÙ† Ø¯Ùˆ Ø¨Ø±Ø¯Ø§Ø±
    cosineSimilarity(vecA, vecB) {
        // Ø¬Ù…Ø¹ Ø¢ÙˆØ±ÛŒ ØªÙ…Ø§Ù… Ú©Ù„ÛŒØ¯Ù‡Ø§
        const allKeys = new Set([...Object.keys(vecA), ...Object.keys(vecB)]);
        
        let dotProduct = 0;
        let normA = 0;
        let normB = 0;
        
        for (const key of allKeys) {
            const a = vecA[key] || 0;
            const b = vecB[key] || 0;
            
            dotProduct += a * b;
            normA += a * a;
            normB += b * b;
        }
        
        if (normA === 0 || normB === 0) {
            return 0;
        }
        
        return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
    }
    
    // Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† ØªØ·Ø§Ø¨Ù‚ Ø¯Ø± FAQ
    findBestMatch(query, faqData, threshold = 0.3) {
        if (!faqData || faqData.length === 0) {
            return null;
        }
        
        // Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„
        const queryTokens = this.preprocess(query);
        const queryVector = this.buildTFVector(queryTokens);
        
        // Ù…Ø­Ø§Ø³Ø¨Ù‡ IDF Ø¨Ø±Ø§ÛŒ FAQ (Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø¨Ø§Ø´Ø¯)
        const documents = faqData.map(faq => ({
            tokens: this.preprocess(faq.question),
            faq: faq
        }));
        
        const idf = this.calculateIDF(documents);
        
        let bestMatch = null;
        let bestScore = 0;
        
        // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ø¨Ø§ Ù‡Ø± Ø³ÙˆØ§Ù„ FAQ
        for (const doc of documents) {
            // Ø³Ø§Ø®Øª Ø¨Ø±Ø¯Ø§Ø± TF Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„ FAQ
            const docVector = this.buildTFVector(doc.tokens);
            
            // Ø§Ø¹Ù…Ø§Ù„ IDF Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ TF-IDF
            const queryTFIDF = {};
            const docTFIDF = {};
            
            // Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±
            for (const token in queryVector) {
                queryTFIDF[token] = queryVector[token] * (idf[token] || 1);
            }
            
            // Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„ FAQ
            for (const token in docVector) {
                docTFIDF[token] = docVector[token] * (idf[token] || 1);
            }
            
            // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª
            const similarity = this.cosineSimilarity(queryTFIDF, docTFIDF);
            
            // Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† ØªØ·Ø§Ø¨Ù‚
            if (similarity > bestScore) {
                bestScore = similarity;
                bestMatch = {
                    question: doc.faq.question,
                    answer: doc.faq.answer,
                    score: similarity,
                    tokens: doc.tokens
                };
            }
        }
        
        // Ø§Ú¯Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Ø¢Ø³ØªØ§Ù†Ù‡ Ø¨Ø§Ø´Ø¯
        if (bestScore >= threshold) {
            console.log(`ğŸ” ØªØ·Ø§Ø¨Ù‚ FAQ ÛŒØ§ÙØª Ø´Ø¯: ${bestScore.toFixed(3)}`);
            return bestMatch;
        }
        
        console.log(`ğŸ” Ù‡ÛŒÚ† ØªØ·Ø§Ø¨Ù‚ FAQ Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Ø¢Ø³ØªØ§Ù†Ù‡ ${threshold} ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø¨Ù‡ØªØ±ÛŒÙ†: ${bestScore.toFixed(3)})`);
        return null;
    }
    
    // Ø¬Ø³ØªØ¬ÙˆÛŒ Ú†Ù†Ø¯ØªØ§ÛŒÛŒ (Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª)
    findTopMatches(query, faqData, limit = 3, threshold = 0.1) {
        if (!faqData || faqData.length === 0) {
            return [];
        }
        
        // Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„
        const queryTokens = this.preprocess(query);
        const queryVector = this.buildTFVector(queryTokens);
        
        // Ù…Ø­Ø§Ø³Ø¨Ù‡ IDF
        const documents = faqData.map(faq => ({
            tokens: this.preprocess(faq.question),
            faq: faq
        }));
        
        const idf = this.calculateIDF(documents);
        
        const matches = [];
        
        // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ø¨Ø§ Ù‡Ø± Ø³ÙˆØ§Ù„
        for (const doc of documents) {
            const docVector = this.buildTFVector(doc.tokens);
            
            // ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ TF-IDF
            const queryTFIDF = {};
            const docTFIDF = {};
            
            for (const token in queryVector) {
                queryTFIDF[token] = queryVector[token] * (idf[token] || 1);
            }
            
            for (const token in docVector) {
                docTFIDF[token] = docVector[token] * (idf[token] || 1);
            }
            
            const similarity = this.cosineSimilarity(queryTFIDF, docTFIDF);
            
            if (similarity >= threshold) {
                matches.push({
                    question: doc.faq.question,
                    answer: doc.faq.answer,
                    score: similarity,
                    tokens: doc.tokens
                });
            }
        }
        
        // Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø²
        matches.sort((a, b) => b.score - a.score);
        
        // Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø¨Ù‡ØªØ±ÛŒÙ† matches
        return matches.slice(0, limit);
    }
    
    // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ø¨ÛŒÙ† Ø¯Ùˆ Ù…ØªÙ† Ù…Ø³ØªÙ‚ÛŒÙ…
    calculateTextSimilarity(text1, text2) {
        const tokens1 = this.preprocess(text1);
        const tokens2 = this.preprocess(text2);
        
        const vector1 = this.buildTFVector(tokens1);
        const vector2 = this.buildTFVector(tokens2);
        
        return this.cosineSimilarity(vector1, vector2);
    }
}

// ØªØ§Ø¨Ø¹ Ø³Ø±Ø§Ø³Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ø³Ø§ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
function calculateSimilarity(text1, text2) {
    const similarityEngine = new SimilaritySearch();
    return similarityEngine.calculateTextSimilarity(text1, text2);
}

// ØªØ§Ø¨Ø¹ Ø¬Ø³ØªØ¬ÙˆÛŒ FAQ
function searchFAQ(query, faqData, threshold = 0.3) {
    const similarityEngine = new SimilaritySearch();
    return similarityEngine.findBestMatch(query, faqData, threshold);
}

// ØªØ§Ø¨Ø¹ Ø¬Ø³ØªØ¬ÙˆÛŒ Ú†Ù†Ø¯ØªØ§ÛŒÛŒ
function searchFAQMultiple(query, faqData, limit = 3, threshold = 0.1) {
    const similarityEngine = new SimilaritySearch();
    return similarityEngine.findTopMatches(query, faqData, limit, threshold);
}

// Ø§Ú©Ø³Ù¾ÙˆØ±Øª Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§
if (typeof module !== 'undefined' && module.exports) {
    module.exports = {
        SimilaritySearch,
        calculateSimilarity,
        searchFAQ,
        searchFAQMultiple
    };
}
